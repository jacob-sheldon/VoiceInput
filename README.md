# Voix

> A macOS voice input application - Hold Command to speak, release to type.

Voix is a menu bar application that transcribes your voice using OpenAI's Whisper model and injects the text directly into any active text field. No internet required, no clipboard interference.

![Status](https://img.shields.io/badge/macOS-13%2B-blue)
![Electron](https://img.shields.io/badge/Electron-26.6.10-purple)
![License](https://img.shields.io/badge/License-MIT-green)

## Features

- **Global Command Key Trigger** - Hold âŒ˜ to speak, release to transcribe
- **Local Speech Recognition** - Uses whisper.cpp for offline, privacy-preserving transcription
- **Direct Text Injection** - Bypasses clipboard using macOS Accessibility API
- **Menu Bar App** - Runs unobtrusively in your menu bar
- **Native Performance** - C++/Objective-C++ modules for low-latency hotkey monitoring

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Hold âŒ˜ Key     â”‚â”€â”€â”€â”€â–¶â”‚ Audio Record â”‚â”€â”€â”€â”€â–¶â”‚ Whisper STT â”‚â”€â”€â”€â”€â–¶â”‚ Text Inject  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚                                      â”‚
                              â–¼                                      â–¼
                        "Listening..."                         Into Active Field
```

## System Requirements

- **macOS**: 13.0 or later (Ventura, Sonoma, Sequoia)
- **Architecture**: Apple Silicon (arm64) or Intel (x64)
- **Node.js**: 18.0 or later
- **Xcode Command Line Tools**: For building native modules

## Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Build Native Modules

```bash
npm run build:native
```

### 3. Install whisper.cpp

```bash
npm run install:whisper
```

### 4. Download Whisper Model

Download at least one model (base is recommended for speed/accuracy balance). Models are stored under your app data directory (macOS: `~/Library/Application Support/Voix/models`):

```bash
# Base model (recommended - ~140MB)
npm run download:model base

# Small model (slower, more accurate - ~460MB)
npm run download:model small

# Medium model (higher accuracy - ~1.4GB)
npm run download:model medium

# Large v3 model (best accuracy - ~2.9GB)
npm run download:model large-v3
```

### 5. Build & Run

```bash
npm run build
npm start
```

The app will appear in your menu bar (âŒ˜).

## Usage

1. Click on any text input field in any application (TextEdit, Notes, browser, etc.)
2. Hold the **Command key (âŒ˜)**
3. A status indicator appears showing "Listening..." with a red dot
4. Speak your text clearly
5. Release the Command key
6. The transcribed text will be automatically inserted into the text field

## First Run - Accessibility Permission

On first launch, you'll see a permission request window. Voix requires Accessibility permission to:

- Monitor the Command key globally
- Inject text into focused fields

Click **"Open System Settings"** and enable Voix under **Privacy & Security â†’ Accessibility**.

## Project Structure

```
Voix/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/                    # Electron Main Process (TypeScript)
â”‚   â”‚   â”œâ”€â”€ main.ts              # App lifecycle, coordination
â”‚   â”‚   â”œâ”€â”€ types.ts             # AppState type definitions
â”‚   â”‚   â””â”€â”€ whisper/
â”‚   â”‚       â””â”€â”€ engine.ts        # Whisper STT integration
â”‚   â”œâ”€â”€ preload/
â”‚   â”‚   â””â”€â”€ preload.ts           # IPC bridge (secure)
â”‚   â”œâ”€â”€ renderer/                # UI Process
â”‚   â”‚   â”œâ”€â”€ index.html           # Status window
â”‚   â”‚   â”œâ”€â”€ permission.html      # Permission request
â”‚   â”‚   â”œâ”€â”€ permission.js        # Permission handling
â”‚   â”‚   â””â”€â”€ ui.ts                # UI logic
â”‚   â””â”€â”€ native/                  # Native Addons (C++/Obj-C++)
â”‚       â”œâ”€â”€ hotkey/              # Command key monitor
â”‚       â”‚   â””â”€â”€ mac/
â”‚       â”‚       â””â”€â”€ hotkey_monitor_mac.mm
â”‚       â”œâ”€â”€ audio/               # Native audio recorder
â”‚       â”‚   â””â”€â”€ mac/
â”‚       â”‚       â””â”€â”€ audio_recorder_mac.mm
â”‚       â””â”€â”€ injection/           # Text injection
â”‚           â””â”€â”€ mac/
â”‚               â””â”€â”€ text_injection_mac.mm
â”œâ”€â”€ scripts/                     # Build & setup scripts
â”œâ”€â”€ models/                      # Whisper models (gitignored)
â”œâ”€â”€ native-deps/                 # whisper.cpp (gitignored)
â””â”€â”€ build/Release/               # Compiled .node files
```

## Architecture

### Electron Main Process
- Manages application lifecycle
- Creates tray icon and status window
- Coordinates between native modules
- Handles state transitions

### Native Modules

#### Hotkey Monitor (`hotkey_monitor.node`)
Uses macOS Event Taps (`CGEventTapCreate`) to globally monitor Command key events without interfering with normal shortcuts.

**Location**: `src/native/hotkey/mac/hotkey_monitor_mac.mm:140`

#### Audio Recorder (`audio_recorder.node`)
Uses `AVAudioEngine` for native audio capture to in-memory buffers.

**Location**: `src/native/audio/mac/audio_recorder_mac.mm`

#### Text Injection (`text_injection.node`)
Uses `AXUIElement` API to directly inject text into the focused element, bypassing the clipboard.

**Location**: `src/native/injection/mac/text_injection_mac.mm`

### Whisper Engine
Spawns whisper.cpp as a child process, passes audio data, receives transcription results.

## Development

### Build Commands

```bash
# Build native modules only
npm run build:native

# Build TypeScript only
npm run build:main
npm run build:renderer
npm run build:preload

# Build everything
npm run build

# Run in development
npm run dev

# Package for distribution
npm run dist:mac
```

### Git Worktree Workflow

This project uses git worktree for parallel feature development:

1. Create a new worktree for a feature:
   ```bash
   git worktree add -b feature/your-feature-name ../Voix-feature main
   ```

2. Navigate to the worktree:
   ```bash
   cd ../Voix-feature
   ```

3. Make your changes and commit in the worktree:
   ```bash
   git add .
   git commit -m "feat: description of your changes"
   ```

4. Push the feature branch:
   ```bash
   git push -u origin feature/your-feature-name
   ```

5. List all worktrees:
   ```bash
   git worktree list
   ```

6. Remove worktree after merge:
   ```bash
   git worktree remove ../Voix-feature
   ```

### Project Status

| Component | Status |
|-----------|--------|
| Command Key Monitoring | âœ… Working |
| Audio Recording | âœ… Working |
| Whisper Transcription | âœ… Working |
| Text Injection | âœ… Working |
| Status Window UI | âœ… Working |
| Permission Flow | âœ… Working |

### Recent Fixes

**v1.0.0** - Fixed hotkey monitor not starting when accessibility permission was already granted. The monitor now starts automatically on app launch when permission exists.

## Development Roadmap

### Upcoming Features

| Feature | Status | Priority |
|---------|--------|----------|
| Chinese Language Support | ğŸ“‹ Planned | High |

#### Chinese Language Support
- [ ] Remove `-l` language flag to enable auto-detection
- [ ] Download general Whisper models (without `.en` suffix)
- [ ] Update model path logic for multi-language models
- [ ] Update documentation for Chinese users

## Troubleshooting

### Native Module Build Fails

**Install Xcode Command Line Tools:**
```bash
xcode-select --install
```

### App Not Responding to Command Key

1. **Check Accessibility Permission:**
   - System Settings â†’ Privacy & Security â†’ Accessibility
   - Ensure Voix is enabled

2. **Check Console Logs:**
   - Look for "Hotkey monitoring started" message
   - Run from terminal to see logs: `npm start`

3. **Verify Native Module:**
   ```bash
   ls build/Release/hotkey_monitor.node
   ```

### Whisper Not Transcribing

1. **Verify whisper.cpp Installation:**
   ```bash
   ls native-deps/whisper.cpp/main
   ```

2. **Download Model:**
   ```bash
   npm run download:model base
   ls models/ggml-base.bin
   ```

### Text Not Inserting

- Make sure you click in a text field before speaking
- Some apps may have restrictions on external text injection
- Try in TextEdit or Notes first to confirm functionality

## Configuration

Edit `src/main/main.ts` to configure Whisper:

```typescript
this.whisperEngine = new WhisperEngine({
  model: 'base',     // 'base' | 'small' | 'medium' | 'large-v3'
  language: 'en',    // Language code (auto-detect if not specified)
  threads: 4         // Number of CPU threads for transcription
});
```

## Model Comparison

| Model | Size | Speed | Accuracy |
|-------|------|-------|----------|
| base | 140MB | âš¡âš¡ | Very Good |
| small | 460MB | âš¡ | Excellent |
| medium | 1.4GB | ~ | Outstanding |
| large-v3 | 2.9GB | ~ | Best |

## License

MIT License - see LICENSE file for details.

## Acknowledgments

- [whisper.cpp](https://github.com/ggerganov/whisper.cpp) - OpenAI Whisper in C/C++
- [Electron](https://www.electronjs.org/) - Cross-platform desktop framework
- [NAN](https://github.com/nodejs/nan) - Native Abstractions for Node.js

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.
